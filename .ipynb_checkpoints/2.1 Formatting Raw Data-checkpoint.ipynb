{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e8d4961",
   "metadata": {},
   "source": [
    "# 2 Data Preparation\n",
    "## 2.1 Formatting Raw Data\n",
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bfb9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f88d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset.\n",
    "raw_data = pd.read_excel(r'C:\\Users\\evamb\\OneDrive\\Documents\\Github\\MAPrecipData\\Precipitation Database 10.19.xls')\n",
    "#raw_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095bcda",
   "metadata": {},
   "source": [
    "### Subdivide data into tables\n",
    "\n",
    "By making each table separate, I can add data from other sources in a modular fashion without cluttering up every other table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffba0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new table to hold Basin data.\n",
    "basin_data = raw_data[['Region', 'Basin Name']]\n",
    "unique_basins = basin_data.drop_duplicates()\n",
    "unique_basins = unique_basins.sort_values(by=['Region', 'Basin Name']) # Alphabetical sorting is enforced.\n",
    "#unique_basins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8779755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new table to hold Station data.\n",
    "station_data = raw_data[['Region', 'Basin Name', 'CITY', 'STATION']]\n",
    "unique_stations = station_data.drop_duplicates()\n",
    "unique_stations = unique_stations.sort_values(by=['STATION']) # Alphabetical sorting is enforced.\n",
    "#unique_stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb69413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new table to hold precipitation data\n",
    "precipitation_data = raw_data.iloc[:,:-4]\n",
    "#precipitation_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d000a2",
   "metadata": {},
   "source": [
    "### Flatten precipitation table\n",
    "\n",
    "Tabular data can be 'flat', meaning the predictor variables are included as columns and related to each outcome value. Pulling these predictor variables out into a nested format produces an indexed table. A multi-indexed format allows the user to select and sub-select specific datapoints by their characteristics (the indices) instead of their position, but a flat format is required build predictive models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f862aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten precip data by month\n",
    "precipitation_flat = precipitation_data.iloc[:,2:].unstack() # Unstack/flatten precip data only.\n",
    "precipitation_flat = precipitation_flat.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad1e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create month list w/ numeric values. \n",
    "# This will be a new column added to the unstacked precip data.\n",
    "# 1 = Jan, 2 = Feb, etc.\n",
    "months_flat = len(precipitation_data)*[1,2,3,4,5,6,7,8,9,10,11,12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d14cbaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the station and year twelve times for every row to the appropriate list.\n",
    "# These will be new columns added to the unstacked precip data.\n",
    "\n",
    "stations_flat = []\n",
    "years_flat = []\n",
    "\n",
    "table_length = len(precipitation_data)\n",
    "\n",
    "for row in range(0, table_length):\n",
    "    station_name = [precipitation_data.iloc[row,0]] # Select station name as list element.\n",
    "    dozen_stations = station_name * 12\n",
    "    stations_flat = stations_flat + (dozen_stations)\n",
    "    \n",
    "    years = [precipitation_data.iloc[row,1]] # Select year.\n",
    "    dozen_years = years * 12\n",
    "    years_flat = years_flat + (dozen_years)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "521bd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to a dictionary.\n",
    "data = {'Station': stations_flat,\n",
    "        'Year': years_flat,\n",
    "        'Month': months_flat,\n",
    "        'Precipitation': precipitation_flat}\n",
    "\n",
    "# Convert the dictionary to a completely flattened dataframe.\n",
    "precipitation_flat = pd.DataFrame(data)\n",
    "#precipitation_flat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0a1a0",
   "metadata": {},
   "source": [
    "### Export data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f7bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data. Indices not preserved.\n",
    "precipitation_flat.to_csv(r'C:\\Users\\evamb\\OneDrive\\Documents\\Github\\MAPrecipData\\Data_Products\\precipitation_flat.csv', index=False)\n",
    "unique_stations.to_csv(r'C:\\Users\\evamb\\OneDrive\\Documents\\Github\\MAPrecipData\\Data_Products\\unique_stations.csv', index=False)\n",
    "unique_basins.to_csv(r'C:\\Users\\evamb\\OneDrive\\Documents\\Github\\MAPrecipData\\Data_Products\\unique_basins.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
